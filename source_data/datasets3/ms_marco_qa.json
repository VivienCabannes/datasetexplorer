{
    "name": "MS MARCO QA",
    "summary": "A large-scale machine reading comprehension dataset from Bing search. It contains 1,010,916 real anonymized queries, each with a set of retrieved passages and human-generated answers&#8203;:contentReference[oaicite:13]{index=13}. About 182k questions have well-formed answers, the rest have extracted answers&#8203;:contentReference[oaicite:14]{index=14}&#8203;:contentReference[oaicite:15]{index=15}.",
    "size": "~1,010,916 query-passages pairs (approx 8.8M passages)&#8203;:contentReference[oaicite:16]{index=16}; 182,669 questions with manually generated answers&#8203;:contentReference[oaicite:17]{index=17}. The v2.1 training set has ~808k queries.",
    "download": "https://microsoft.github.io/msmarco/ (registration required); also available on the MS MARCO leaderboard site and on HuggingFace (`ms_marco` for passages and QA).",
    "companion": "https://arxiv.org/abs/1611.09268 (Nguyen et al. 2016, MS MARCO paper)",
    "notes": "Answers are often a segment from a passage or a human-written summary of multiple passages. Used for passage ranking and reading comprehension. It includes yes/no and unanswerable questions as well.",
    "tags": [
        "human",
        "QA",
        "compilation",
        "answer:verifiable",
        "question:human",
        "answer:crowd-sourced",
        "domain:nlp"
    ]
}
