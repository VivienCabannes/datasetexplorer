{"name": "ShARC", "summary": "Shaping Answers with Rules through Conversation is a conversational QA dataset (32k instances) about understanding rule texts (like government policies). It involves an initial question and possibly follow-up Q&A turns to clarify conditions before giving a final yes/no/inquire answer. It has 948 distinct scenarios (snippet + user question) and ~32k QA turns&#8203;:contentReference[oaicite:53]{index=53}.", "size": "~32,000 QA instances (including follow-ups) from 948 dialog trees. Train ~22.5k, Dev ~2.5k, Test ~7k instances.", "download": "Data on GitHub: https://sharc-data.github.io (ShARC v1.0 JSON). Also on HuggingFace as `sharc`.", "companion": "https://aclanthology.org/P19-1443 (Saeidi et al. 2018, ShARC paper)", "notes": "Unique for its conversational logic: The system must infer if the user\u2019s scenario satisfies conditions in the rule text. The answer can be \"Yes\", \"No\", or a follow-up question to ask for missing info. Dialogues are tree-structured. Annotations include the underlying rule text (snippet) and scenario (user background info).", "tags": ["crowd-sourced", "dialog", "atomic", "with rationale", "question:crowd-sourced", "answer:crowd-sourced", "rationale:human", "domain:nlp"]}