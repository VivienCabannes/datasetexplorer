{
    "name": "MCTest",
    "summary": "One of the early machine comprehension datasets (2013) with 660 short fictional stories written for the task&#8203;:contentReference[oaicite:36]{index=36}. Each story has 4 multiple-choice questions (with 4 options each). Aimed at elementary-level text understanding and reasoning.",
    "size": "660 stories, 2640 questions (4 Q per story)&#8203;:contentReference[oaicite:37]{index=37}&#8203;:contentReference[oaicite:38]{index=38}, with 4 answer choices per question.",
    "download": "Microsoft MCTest: http://research.microsoft.com/mctest (includes dataset as TSV); also on HuggingFace (`mctest`).",
    "companion": "https://www.aclweb.org/anthology/D14-1052 (Richardson et al. 2013, MCTest paper)",
    "notes": "Stories and questions were crowd-sourced to be answerable from the text alone, targeting understanding by 7-year-old level readers&#8203;:contentReference[oaicite:39]{index=39}. While small in size, it was influential as a controlled reading comprehension test with open research usage.",
    "tags": [
        "crowd-sourced",
        "QA",
        "atomic",
        "answer:verifiable",
        "question:crowd-sourced",
        "answer:crowd-sourced",
        "domain:nlp"
    ]
}
