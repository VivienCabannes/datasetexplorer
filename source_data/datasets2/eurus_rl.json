{
  "name": "Eurus-RL",
  "summary": "Eurus-RL is a high-quality reinforcement learning (RL) training dataset comprising approximately 480,537 samples of mathematics and coding problems, each accompanied by verifiable outcomes. The dataset aggregates problems from several sources:",
  "Mathematics": "Advanced reasoning models like Qwen-QwQ were utilized to filter out unsolvable problems, unmatchable questions, or those with incorrect answers. Multiple-choice questions were reformatted into open-ended questions.",
  "Coding": "Duplicates were removed to maintain uniqueness.",
  "size": "Approximately 480,537 samples, totaling around 2 GB.",
  "download": "The dataset is available for download at [https://huggingface.co/datasets/PRIME-RL/Eurus-2-RL-Data](https://huggingface.co/datasets/PRIME-RL/Eurus-2-RL-Data).",
  "companion": "The dataset is associated with the paper \"Process Reinforcement through Implicit Rewards,\" accessible at [https://arxiv.org/abs/2502.01456](https://arxiv.org/abs/2502.01456).",
  "notes": "Eurus-RL includes multiple datasets with corresponding training recipes, facilitating research in reinforcement learning for complex reasoning tasks. The dataset's construction involved rigorous validation processes to ensure the correctness of solutions, making it suitable for training models that require verifiable outcomes.",
  "tags": [
    "human",
    "compilation",
    "filtration",
    "mathematics",
    "coding",
    "reinforcement learning"
  ]
}