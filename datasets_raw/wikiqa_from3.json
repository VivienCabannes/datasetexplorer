{"name": "WikiQA", "summary": "A small open-domain QA dataset of question and sentence pairs from Bing query logs (2015). It has 3,047 factoid questions, each with a set of candidate sentences from Wikipedia, among which ~1,473 are labeled as answer sentences&#8203;:contentReference[oaicite:54]{index=54}. The task is usually answer sentence selection (find which sentence contains the answer).", "size": "3,047 questions, 29,258 sentences in total&#8203;:contentReference[oaicite:55]{index=55}. On average ~9.6 candidate sentences per question; 1 or more marked correct answers (1.5 on avg for answerable questions).", "download": "Microsoft Research release (WikiQA corpus on Microsoft site and Kaggle). Also on HuggingFace as `wiki_qa`.", "companion": "https://www.aclweb.org/anthology/D15-1237 (Yang et al. 2015, WikiQA paper)", "notes": "All questions are real user questions (mostly factoid) originally intended to be answered by Wikipedia. Roughly 40% of questions have no correct answer in the provided sentences (labeled none). Often used to evaluate answer sentence selection models. It\u2019s notably smaller than other QA sets.", "tags": ["human", "QA", "filtration", "answer:verifiable", "question:human", "answer:human", "domain:nlp"]}