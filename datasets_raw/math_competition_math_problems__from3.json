{"name": "MATH (Competition Math Problems)", "summary": "A dataset of 12,500 difficult high school mathematics competition problems with full step-by-step solutions&#8203;:contentReference[oaicite:77]{index=77}. Problems range in topics (algebra, geometry, calculus) and require written mathematical reasoning. Each problem\u2019s final answer is typically a short number or expression, and a detailed solution (rationale) is provided.", "size": "12,500 problems (7,500 train, 500 val, 5,000 test)&#8203;:contentReference[oaicite:78]{index=78}, each with a detailed solution and an answer.", "download": "From the official GitHub (hendrycks/math) or on HuggingFace `hendrycks_math`.", "companion": "https://arxiv.org/abs/2103.03874 (Hendrycks et al. 2021, MATH dataset NeurIPS paper)", "notes": "The solutions are often several paragraphs of LaTeX describing the reasoning. This dataset evaluates advanced mathematical problem solving. Performance is measured by exact match on the final answer. It\u2019s extremely challenging: GPT-3 and similar models have low accuracy, making it a key benchmark for program-of-thought or tool-use techniques.", "tags": ["compilation", "QA", "benchmark", "with rationale", "question:human", "answer:human", "rationale:human", "domain:mathematics"]}