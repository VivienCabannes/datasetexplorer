{
    "name": "WinoGrande",
    "summary": "A large-scale Winograd Schema Challenge dataset (44k pronoun resolution problems) designed to mitigate annotation artifacts&#8203;:contentReference[oaicite:62]{index=62}. Each problem is a sentence with an ambiguous pronoun referring to one of two entities, and the task is to choose the correct referent. WinoGrande is adversarially filtered and much larger than the original WSC.",
    "size": "44,000 problems (train 40k, dev 1.2k, test 1.8k)&#8203;:contentReference[oaicite:63]{index=63}.",
    "download": "https://mosaic.allenai.org/projects/winogrande (data available via AI2 download). Also on HuggingFace `winogrande`.",
    "companion": "https://aaai.org/ojs/index.php/AAAI/article/view/7005 (Sakaguchi et al. 2020, WinoGrande paper)",
    "notes": "Each question provides a sentence with a pronoun blank and two answer choices (the two nouns). Example: \"The trophy didn't fit in the suitcase because ___ was too big.\" (Options: trophy or suitcase). WinoGrande increased scale by crowdsourcing and applying bias reduction so that statistical cues are minimized. It\u2019s a commonsense reasoning test included in some LLM evals.",
    "tags": [
        "crowd-sourced",
        "QA",
        "atomic",
        "question:crowd-sourced",
        "answer:crowd-sourced",
        "domain:nlp"
    ]
}
