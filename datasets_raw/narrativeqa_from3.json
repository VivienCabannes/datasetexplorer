{
    "name": "NarrativeQA",
    "summary": "A reading comprehension dataset focusing on long narratives (books and movie scripts). It has ~46,765 QA pairs&#8203;:contentReference[oaicite:31]{index=31} derived from 1,567 stories (books or scripts)&#8203;:contentReference[oaicite:32]{index=32}. Questions require understanding entire narratives; answers are free-form summaries rather than exact spans.",
    "size": "1567 documents (book or script) and 46,765 QA pairs&#8203;:contentReference[oaicite:33]{index=33}. (Train 38,000, Dev 4,500, Test 4,500).",
    "download": "Publicly available via DeepMind (narrativeqa.org) and on HuggingFace `narrative_qa`.",
    "companion": "https://arxiv.org/abs/1712.07040 (Kocisky et al. 2018, NarrativeQA paper)",
    "notes": "Two modes: summaries and full stories. Each story has a human-written summary. Questions were authored based on the summaries, then answers were written given the full story. Tasks include answering from summary (abstractive RC) or from full story (challenging long context comprehension).",
    "tags": [
        "crowd-sourced",
        "QA",
        "atomic",
        "question:crowd-sourced",
        "answer:crowd-sourced",
        "answer:human",
        "domain:nlp"
    ]
}
