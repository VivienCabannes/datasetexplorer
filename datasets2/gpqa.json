{
  "name": "GPQA",
  "summary": "The Graduate-Level Google-Proof Q&A (GPQA) is a benchmark dataset designed to evaluate the capabilities of language models and scalable oversight mechanisms through 448 challenging multiple-choice questions in biology, physics, and chemistry.",
  "size": "448 multiple-choice questions",
  "download": "https://github.com/idavidrein/gpqa",
  "companion": "https://arxiv.org/abs/2311.12022",
  "notes": "GPQA's questions are crafted by domain experts to be exceptionally difficult, with experts achieving 65% accuracy and highly skilled non-experts only 34%, despite unrestricted web access and extensive time per question. The dataset is 'Google-proof,' making it a robust tool for assessing advanced reasoning and knowledge in language models. Notably, as of March 2024, Claude 3 Opus achieved approximately 60% accuracy on this benchmark, highlighting rapid advancements in AI capabilities.",
  "tags": [
    "human",
    "QA",
    "benchmark",
    "answer:verifiable",
    "question:human",
    "answer:human",
    "mathematics",
    "physics"
  ]
}
  