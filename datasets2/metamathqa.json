{
  "name": "MetaMathQA",
  "summary": "MetaMathQA is a dataset comprising approximately 395,000 mathematical problems, each paired with detailed solutions. The dataset was constructed by augmenting the training sets of GSM8K and MATH through a process called \"question bootstrapping,\" which involves generating new questions by rephrasing existing ones and creating forward and backward reasoning paths. This approach aims to enhance the diversity and quality of mathematical problems available for training large language models (LLMs).",
  "size": "Approximately 395,000 samples, totaling around 200 MB.",
  "download": "The dataset is available for download at [https://huggingface.co/datasets/meta-math/MetaMathQA](https://huggingface.co/datasets/meta-math/MetaMathQA).",
  "companion": "The dataset is introduced in the paper \"MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models,\" accessible at [https://arxiv.org/abs/2309.12284](https://arxiv.org/abs/2309.12284).",
  "notes": "MetaMathQA was developed to improve the mathematical reasoning capabilities of LLMs by providing a diverse set of problems with varying reasoning paths. The dataset has been utilized to fine-tune models such as MetaMath-7B, which demonstrated significant performance improvements on benchmarks like GSM8K and MATH.",
  "tags": [
    "synthetic",
    "QA",
    "compilation",
    "answer:verifiable",
    "question:synthetic",
    "answer:synthetic",
    "mathematics"
  ]
}