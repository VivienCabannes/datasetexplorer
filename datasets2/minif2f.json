{
  "name": "MiniF2F",
  "summary": "MiniF2F is a benchmark dataset designed to evaluate the performance of neural theorem provers across multiple formal systems. It comprises 488 Olympiad-level mathematics problems sourced from competitions such as the American Invitational Mathematics Examination (AIME), American Mathematics Competitions (AMC), and the International Mathematical Olympiad (IMO). Each problem is provided with both informal descriptions and formal statements in systems including Metamath, Lean, and partially in Isabelle and HOL Light. The dataset aims to facilitate advancements in automated theorem proving by offering a unified test suite for cross-system evaluation. citeturn0academia23",
  "size": "488 problems with formal and informal statements.",
  "download": "The dataset is available for download at [https://github.com/facebookresearch/miniF2F](https://github.com/facebookresearch/miniF2F).",
  "companion": "The dataset is introduced in the paper \"MiniF2F: a cross-system benchmark for formal Olympiad-level mathematics,\" accessible at [https://arxiv.org/abs/2109.00110](https://arxiv.org/abs/2109.00110).",
  "notes": "MiniF2F serves as a stepping stone towards achieving the IMO Grand Challenge, which envisions an AI capable of winning a gold medal in the International Mathematical Olympiad through formal-to-formal problem-solving. The benchmark's cross-platform nature and range of difficulty levels make it a valuable resource for developing and evaluating neural theorem proving systems. citeturn0academia23",
  "tags": [
    "human",
    "QA",
    "benchmark",
    "answer:verifiable",
    "question:human",
    "answer:human",
    "mathematics"
  ]
}