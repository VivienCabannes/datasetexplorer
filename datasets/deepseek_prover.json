{
    "name": "DeepSeek-Prover-V1",
    "size": "27,000 samples, 6 MB",
    "download": "https://huggingface.co/datasets/deepseek-ai/DeepSeek-Prover-V1",
    "companion": "https://arxiv.org/abs/2405.14333",
    "summary": "Synthetic dataset of Lean proofs generated by DeepSeek, solving half of miniF2F."
}

Here's the completed dataset card for **DeepSeek-Prover-V1**:

- **name**: DeepSeek-Prover-V1

- **summary**: DeepSeek-Prover-V1 is a synthetic dataset comprising approximately 8 million formal mathematical statements paired with their corresponding proofs, generated by DeepSeek. The dataset focuses on formalizing and proving problems from high-school and undergraduate-level mathematical competitions, including those found in the miniF2F benchmark. The formal proofs are constructed in Lean 4, a modern proof assistant language. This dataset aims to advance the capabilities of large language models (LLMs) in formal theorem proving by providing a substantial corpus of formalized mathematics. 

- **size**: Approximately 8 million samples, totaling around 6 MB. 

- **download**: The dataset is available for download at [https://huggingface.co/datasets/deepseek-ai/DeepSeek-Prover-V1](https://huggingface.co/datasets/deepseek-ai/DeepSeek-Prover-V1). 

- **companion**: The dataset is introduced in the paper "DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale Synthetic Data," accessible at [https://arxiv.org/abs/2405.14333](https://arxiv.org/abs/2405.14333). 

- **notes**: The dataset was generated through a process that involved translating natural language problems into formal statements, filtering out low-quality statements, and generating proofs to create synthetic data. After fine-tuning the DeepSeekMath 7B model on this dataset, the model achieved whole-proof generation accuracies of 46.3% with 64 samples and 52% cumulatively on the Lean 4 miniF2F test, surpassing the baseline GPT-4 at 23.0% with 64 samples and a tree search reinforcement learning method at 41.0%. Additionally, the model successfully proved 5 out of 148 problems in the Lean 4 Formalized International Mathematical Olympiad (FIMO) benchmark, while GPT-4 failed to prove any. 

- **tags**: "synthetic", "theorem proving", "Lean 4", "mathematics", "formal proofs"

This card provides an overview of the DeepSeek-Prover-V1 dataset, highlighting its structure, content, and significance in advancing research in formal mathematics and automated theorem proving. 