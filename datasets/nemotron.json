{
    "name": "Nemotron Post-Training Dataset v1",
    "size": "15,000,000 samples, 6 GB.",
    "download": "https://huggingface.co/datasets/nvidia/Llama-Nemotron-Post-Training-Dataset-v1",
    "companion": "https://arxiv.org/abs/2502.00203",
    "notes": "Developed to fine-tune models for improved accuracy and reliability.",
    "summary": "We do not have too many details on this datasets, it seems to have been curated from Llama, Qwen and DeepSeek answers."
}