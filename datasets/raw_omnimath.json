{
  "name": "Omni-MATH",
  "summary": "_âš  Use card with caution_ <br>A benchmark for assessing LLMs' mathematical reasoning using Olympiad-level problems from regional to international competitions.",
  "size": "4,428 problems (~7 MB).",
  "download": "https://huggingface.co/datasets/KbsdJames/Omni-MATH",
  "companion": "https://arxiv.org/abs/2410.07985",
  "notes": "The dataset spans over 33 mathematical sub-domains and includes problems of varying difficulty. It was designed to challenge advanced LLMs in mathematical reasoning.",
  "tags": [
    "human",
    "QA",
    "atomic",
    "answer:verifiable",
    "question:human",
    "answer:human",
    "mathematics"
  ]
}
