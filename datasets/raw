{
  "name": "Stack-Edu",
  "summary": "A 125B token dataset of educational code filtered from The Stack v2, curated for training language models.",
  "size": "Approximately 125 billion tokens.",
  "date": "2025-02-04",
  "download": "https://huggingface.co/datasets/HuggingFaceTB/stack-edu",
  "companion": "https://arxiv.org/abs/2502.02737",
  "notes": "Stack-Edu was curated using a classifier-based filtering strategy to retain high-quality educational programming content. It includes code from 15 programming languages, with Python, C++, and Markdown being the most prominent. The dataset was instrumental in training the SmolLM2 model.",
  "tags": [
    "human",
    "monolithic",
    "filtration",
    "programming"
  ]
}
