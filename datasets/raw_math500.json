{
  "name": "MATH-500",
  "summary": "A curated subset of 500 problems from the MATH benchmark, designed to evaluate mathematical problem-solving abilities of language models.",
  "size": "500 problems.",
  "date": "2023-11-15",
  "download": "https://huggingface.co/datasets/HuggingFaceH4/MATH-500",
  "companion": "https://arxiv.org/abs/2103.03874",
  "notes": "The dataset includes problems across various topics such as algebra, geometry, and calculus, providing a comprehensive evaluation framework for mathematical reasoning in AI systems.",
  "tags": [
    "human",
    "QA",
    "compilation",
    "answer:verifiable",
    "with rationale",
    "question:human",
    "answer:human",
    "rationale:human",
    "mathematics"
  ]
}
