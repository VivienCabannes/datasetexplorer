{
    "name": "Open-R1-220k",
    "size": "225,000 samples, 8 GB.",
    "download": "https://huggingface.co/datasets/open-r1/OpenR1-Math-220k",
    "notes": "They have other datasets, see https://huggingface.co/open-r1",
    "summary": "This part of an ongoing effort by HuggingFace to reproduce DeepSeek R1. Consists of DeepSeek R1 traces answering problems from NuminaMath, verified with Math Verify, a HuggingFace parser to check numerical equality."
}

Here's the completed dataset card for **OpenR1-Math-220k**:

- **name**: OpenR1-Math-220k

- **summary**: OpenR1-Math-220k is a large-scale dataset designed to enhance mathematical reasoning in AI models. It comprises approximately 220,000 math problems, each accompanied by two to four reasoning traces generated by the DeepSeek R1 model. The problems are sourced from NuminaMath 1.5, and the reasoning traces have been verified using Math Verify and, for a subset, Llama-3.3-70B-Instruct as a judge. citeturn0search0

- **size**: The dataset contains approximately 220,000 samples, totaling around 8 GB. citeturn0search0

- **download**: The dataset is available for download at [https://huggingface.co/datasets/open-r1/OpenR1-Math-220k](https://huggingface.co/datasets/open-r1/OpenR1-Math-220k). citeturn0search0

- **notes**: OpenR1-Math-220k is part of an ongoing effort by Hugging Face to reproduce and build upon DeepSeek R1. The dataset includes two splits:
  - **default**: Contains 94,000 problems and achieves the best performance after supervised fine-tuning (SFT).
  - **extended**: Comprises 131,000 samples, incorporating additional data sources like `cn_k12`. While this provides more reasoning traces, performance after SFT is observed to be lower than the `default` subset, likely due to the varying difficulty levels of the questions. citeturn0search0

  The dataset was generated using 512 NVIDIA H100 GPUs, producing approximately 300,000 problem solutions per day. Each problem includes at least one reasoning trace with a correct answer, verified through automated tools and human-like judgment models. citeturn0search0

- **tags**: "synthetic", "QA", "compilation", "answer:verifiable", "with rationale", "question:human", "answer:synthetic", "rationale:synthetic", "mathematics"

This card provides a comprehensive overview of the OpenR1-Math-220k dataset, highlighting its structure, content, and relevance to advancing mathematical reasoning in AI models. 