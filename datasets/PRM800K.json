{
    "name": "PRM800K",
    "size": "800,000 samples,",
    "download": "https://github.com/openai/prm800k",
    "companion": "https://arxiv.org/abs/2305.20050",
    "notes": "Some annotations were reported to be incorrect",
    "summary": "Datasets created by OpenAI by using LLMs to answer question from the MATH datasets, with rationale graded by humnas."
}

Here's the completed dataset card for **PRM800K**:

- **name**: PRM800K

- **summary**: PRM800K is a process supervision dataset developed by OpenAI, containing 800,000 step-level correctness labels for model-generated solutions to problems from the MATH dataset. Each solution is annotated with human feedback at each reasoning step, facilitating the training of process reward models (PRMs) that evaluate intermediate steps in problem-solving. citeturn0search1

- **size**: The dataset comprises 800,000 annotated reasoning steps. citeturn0search1

- **download**: The dataset is available for download at [https://github.com/openai/prm800k](https://github.com/openai/prm800k). citeturn0search1

- **companion**: The dataset is introduced in the paper "Let's Verify Step by Step," accessible at [https://arxiv.org/abs/2305.20050](https://arxiv.org/abs/2305.20050). citeturn0search1

- **notes**: PRM800K was created to support research in training more reliable models for complex multi-step reasoning tasks. It provides step-level human feedback, enabling the development of models that can assess the correctness of each reasoning step. However, some annotations have been reported to be incorrect, which may impact model training and evaluation. citeturn0search5

- **tags**: "human", "QA", "compilation", "answer:verifiable", "with rationale", "question:synthetic", "answer:synthetic", "rationale:human", "mathematics"

This card provides a comprehensive overview of the PRM800K dataset, highlighting its structure, content, and relevance to research in mathematical reasoning and process supervision. 