{
  "name": "GPQA Diamond",
  "summary": "A subset of 198 exceptionally high quality, expert-crafted multiple-choice questions in biology, physics, and chemistry from the GPQA benchmark.",
  "size": "198 multiple-choice questions.",
  "date": "2023-11-20",
  "download": "https://github.com/idavidrein/gpqa",
  "companion": "https://arxiv.org/abs/2311.12022",
  "notes": "The Diamond subset represents the most difficult and highest quality questions within the GPQA benchmark, designed to be 'Google-proof' and requiring deep subject matter expertise. Expert validators achieved 65% accuracy, while highly skilled non-experts reached only 34%, despite unrestricted web access and extended time per question. This subset serves as a rigorous test for assessing advanced reasoning and knowledge in language models.",
  "tags": [
    "crowd-sourced",
    "QA",
    "benchmark",
    "answer:verifiable",
    "with rationale",
    "question:crowd-sourced",
    "answer:crowd-sourced",
    "rationale:crowd-sourced",
    "biology",
    "physics",
    "chemistry"
  ]
}
