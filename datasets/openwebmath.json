{
   "name": "OpenWebMath",
    "size": "6,300,000 samples, 27 GB.",
    "download": "https://huggingface.co/datasets/open-web-math/open-web-math",
    "companion": "https://arxiv.org/abs/2310.06786",
    "summary": "Filtering of CommonCrawl done in 2023, that is considered good quality. Not donwloaded, as FineMath is more recent."
}

Here's the completed dataset card for **OpenWebMath**:

- **name**: OpenWebMath

- **summary**: OpenWebMath is a dataset containing 6.3 million documents of high-quality mathematical text extracted from over 200 billion HTML files in the Common Crawl dataset. It encompasses approximately 14.7 billion tokens and is intended for use in pretraining and finetuning large language models. 

- **size**: The dataset comprises 6.3 million samples, totaling approximately 27 GB. 

- **download**: The dataset is available for download at [https://huggingface.co/datasets/open-web-math/open-web-math](https://huggingface.co/datasets/open-web-math/open-web-math). 

- **companion**: The dataset is introduced in the paper "OpenWebMath: An Open Dataset of High-Quality Mathematical Web Text," accessible at [https://arxiv.org/abs/2310.06786](https://arxiv.org/abs/2310.06786). 

- **notes**: OpenWebMath was curated by filtering the Common Crawl dataset to include only English documents containing mathematical content of high quality. The filtering process involved prefiltering HTML documents, extracting text (including LaTeX content), classifying and filtering content, deduplicating using SimHash, and manual inspection to remove low-quality pages. 

- **tags**: "human", "monolithic", "filtration", "mathematics"

This card provides a comprehensive overview of the OpenWebMath dataset, highlighting its structure, content, and relevance to mathematical language processing research.